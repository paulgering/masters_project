## Loading packages

```{r loadlib, echo = TRUE, results = 'hide', warning = FALSE, message = FALSE}
library(AER) #conduct an overdispersion test on Poisson Models
library(dplyr) #Preparing the data for analysis
library(here) #locate files based on current working directory
library(MASS) #Fit negative binomial regression
library(MuMIn) #Calculate the Akaike Information Criterion (AIC) for each model
library(WebPower) #Conduct power analysis
```

## Prospective Power Analysis

Conducting a prospective power analysis to determine the sample size that would be required to detect a small/medium effect size 

```{r}
baselinerate = 4 #Baseline rate of infant vocab size

#Small effect size

d=0.2

lo=d*(pi/sqrt(3)) 

increase = exp(lo)

slope=(baselinerate+increase)/baselinerate #Calculating the expected slope based on an effect size of 0.2

wp.poisson(n = NULL, exp0 = baselinerate, exp1 = slope, alpha = 0.05, power = 0.8, family = "Bernoulli", alternative="greater")

#Medium effect size

d=0.5

lo=d*(pi/sqrt(3)) 

increase = exp(lo)

slope=(baselinerate+increase)/baselinerate # Calculating the expected slope based on an effect size of 0.5

wp.poisson(n = NULL, exp0 = baselinerate, exp1 = slope, alpha = 0.05, power = 0.8, family = "Bernoulli", alternative="greater")

```

## Load the data 

```{r}
df <- read.csv(here("data"))
```

## Preparing the researcher-coded behaviours 

The below code is used to prepare the counts of researcher-coded behaviours prior to incorporating them into Poisson regression models. The code takes the columns that begin with 12 months, which happens to be the columns containing the counts of researcher-coded behaviours (aside from 12m_length), and mutates them using the following steps: 
1. Adding one to the counts to avoid zero counts 
2. Prorating the counts by Dividing them by the length of the videos at 12 months and multiplying them by 300 (the maximum length of a video)
3. Log transforming the counts to reduce skewness
4. Robust scaling by subtracting the median from each of the values and dividing by the interquartile range of each column 

```{r}
df1 <- df %>%
  mutate(across(
    starts_with("12m_") & !matches("12m_length"),
    ~ (((log(((. + 1) / 12m_length) * 300)) - median(.)) / IQR(.)),
    .names = "{.col}_pro"
  ))
```

## Fitting the models to a Poisson Distribution
Building the models using poisson regressions. 

### Model 0 - Null Model 

```{r}
M0 = glm(18m_cdi_vocab_count ~ condition, family = Poisson, data=df)
```

### Model 1 - Count of infant 'intentional' Prelinguistic Communicative Acts

```{r}
M1 = glm(18m_cdi_vocab_count ~ condition + 12m_pca_count ,family=poisson,data=df1)

summary(M1)
```

### Model 2 - Count of infant 'intentional' Prelinguistic Communicative Acts that elicited a response of any kind

```{r}
M2 = glm(18m_cdi_vocab_count ~ condition + 12m_responses_pca_only_count ,family=poisson,data=df1)

summary(M2)
```

### Model 3 - Count of infant 'intentional Prelinguistic Communicative Acts that elicited a content-light response

```{r}
M3 = glm(18m_cdi_vocab_count ~ condition + 12m_cl_pca_only_count ,family=poisson,data=df1)

summary(M3)
```

### Model 4 - Count of infant 'intentional Prelinguistic Communicative Acts that elicited a semantically contingent response

```{r}
M4 = glm(18m_cdi_vocab_count ~ condition + 12m_sc_pca_only_count ,family=poisson,data=df1)


summary(M4)
```

### Model 5 - A count of (infant 'intentional Prelinguistic Communicative Acts + non-gaze-coordinated vocalisations) that elicited a response of any kind

```{r}
M5 = glm(18m_cdi_vocab_count ~ condition + 12m_responses_all_count ,family=poisson,data=df1)

summary(M5)
```

### Model 6 - A count of (infant 'intentional Prelinguistic Communicative Acts + non-gaze-coordinated vocalisations) that elicited a content-light response

```{r}
M6 = glm(18m_cdi_vocab_count ~ condition + 12m_cl_all_count ,family=poisson,data=df1)

summary(M6)
```

### Model 7 - A count of (infant 'intentional Prelinguistic Communicative Acts + non-gaze-coordinated vocalisations) that elicited a semantically contingent response

```{r}
M7 = glm(18m_cdi_vocab_count ~ condition + 12m_sc_all_count ,family=poisson,data=df1)

summary(M7)
```

## Testing for overdispersion
Determine whether overdispersion has occurred for any of the built models using the dispersiontest function.

```{r}
# Testing for overdispersion in each of the models
dispersiontest(M1)
dispersiontest(M2)
dispersiontest(M3)
dispersiontest(M4)
dispersiontest(M5)
dispersiontest(M6)
dispersiontest(M7)
```

## Negative binomial analyses 
If any of these tests detect overdispersion, a negative binomial regression will be fitted instead.

```{r}
M1_nb = glm.nb(18m_cdi_vocab_count ~ condition + 12m_pca_count ,family=poisson,data=df1)

summary(M1)
```

```{r}
M2_nb = glm.nb(18m_cdi_vocab_count ~ condition + 12m_responses_pca_only_count ,family=poisson,data=df1)

summary(M2)
```

```{r}
M3_nb = glm.nb(18m_cdi_vocab_count ~ condition + 12m_cl_pca_only_count ,family=poisson,data=df1)

summary(M3)
```

```{r}
M4_nb = glm.nb(18m_cdi_vocab_count ~ condition + 12m_sc_pca_only_count ,family=poisson,data=df1)


summary(M4)
```

```{r}
M5_nb = glm.nb(18m_cdi_vocab_count ~ condition + 12m_responses_all_count ,family=poisson,data=df1)

summary(M5)
```

```{r}
M6_nb = glm.nb(18m_cdi_vocab_count ~ condition + 12m_cl_all_count ,family=poisson,data=df1)

summary(M6)
```

```{r}
M7_nb = glm.nb(18m_cdi_vocab_count ~ condition + 12m_sc_all_count ,family=poisson,data=df1)

summary(M7)
```

## Testing Prediction 1: Infants who produce more PCA's will have a alrger vocabulary size at 18 months 

```{r}
anova(M1_nb, M1)
```

If the tests detect overdispersion for any of the models, the models built using a negative binomial regression will be included in this code instead of the models built using a Poisson Regression. 

EXAMPLE: If overdispersion is detected for model 1: 

```{r}
anova(M1, M0)
```

## Testing Prediction 2: The combination of PCA + response will be a better predictor of vocabulary size than all PCAs including those not met with a response 

```{r}
model.sel(M1, M2)
```

## Testing Prediction 3: Infant PCAs that elicit a semantically contingent response will be the strongest predictor of vocabulary over and above other sequences

```{r}
model.sel(M1, M2, M3, M4, M5, M6, M7)
```

## Testing Prediction 4: Infant ‘intentional’ PCAs and non-gaze-coordinated vocalisations that, regardless of infant intent, elicit a semantically contingent response (measure 2c) will predict vocabulary better than those that elicit other responses (measure 2a, any response, or measure 2b, a content light response)

```{r}
model.sel(M5, M6, M7)
```

## Exploratory analysis 1: Assessing the predictive value of content light responses relative to other kinds of responses

```{r}
model.sel(M2, M3, M4)
```

```{r}
model.sel(M5, M6, M7)
```

## Exploratory analysis 2: Assessing the predictive value of Infant intentional PCAs relative to a larger set of behaviours including non-gaze coordinated vocalisations

```{r}
model.sel(M2, M5)
```

```{r}
model.sel(M3, M6)
```

```{r}
model.sel(M4, M7)
```
